## Code :
import cv2
import keyboard
import os
import webbrowser
import random
import time
import face_recognition
# Initialize the camera
cap = cv2.VideoCapture(0)
# Provide the full path to the Haar Cascade classifier file
face_cascade = cv2.CascadeClassifier(r'C:\Users\HP\Downloads\haarcascade_frontalface_default.xml')
# Initialize music playlists based on emotions
playlist_happy = [
    r"C:\Users\HP\Downloads\Narendra(MP)\Dooram Karigina.mp3",
    # Add paths to happy music files
]
playlist_sad = [
    r"C:\Users\HP\Downloads\Narendra(MP)\Pranam Pothunna.mp3",
    # Add paths to sad music files
]
playlist_angry = [
    r"C:\Users\HP\Downloads\Narendra(MP)\Hukum.mp3",
    # Add paths to angry music files
]
current_playlist = playlist_happy  # Default playlist is happy music
current_song = 0  # Initialize the current song index
# Function to play the current song using the default system media player
def play_song():
    song_path = current_playlist[current_song]
# Open the song with the default system media player
    webbrowser.open(song_path)
# Function to randomly switch playlists
def switch_playlist():
    global current_playlist
    random_emotion = random.choice(['happy', 'sad', 'angry'])
    if random_emotion == 'happy':
        current_playlist = playlist_happy
    elif random_emotion == 'sad':
        current_playlist = playlist_sad
    elif random_emotion == 'angry':
        current_playlist = playlist_angry
while True:
# Read a frame from the camera
    ret, frame = cap.read()
# Convert the frame to grayscale for face detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
# Detect faces in the frame using Haar Cascade
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))
# Check if faces are detected
    if len(faces) > 0:
# Randomly switch playlists based on detected emotion (replace with your emotion detection logic)
        switch_playlist()
# Play the current song
        play_song()
# Wait for a key press to move to the next song
        keyboard.wait("space")
# Increment the current song index or loop back to the first song
        current_song = (current_song + 1) % len(current_playlist)
# Display the frame with rectangles around detected faces
    for (x, y, w, h) in faces:
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
# Display the frame
    cv2.imshow('Face Detection Music Player', frame)
# Exit the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
# Release the camera and close all OpenCV windows
cap.release()            
cv2.destroyAllWindows() 
